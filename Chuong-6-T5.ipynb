{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e264c09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CNLTHD\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các thư viện đã được import\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # Tokenizer và Model T5 (dùng cho tóm tắt)\n",
    "import textwrap # textwrap để format văn bản\n",
    "import warnings # warnings để kiểm soát cảnh báo\n",
    "import requests\n",
    "\n",
    "# Tắt cảnh báo không quan trọng từ wikipedia\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='wikipedia')\n",
    "print(\"Các thư viện đã được import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18ff3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu hình:\n",
      "  Model: t5-small\n",
      "  Trang Wikipedia: 'Artificial intelligence' (en)\n",
      "  Độ dài tóm tắt: [50, 300] tokens\n",
      "  Thiết bị: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Cấu hình ---\n",
    "MODEL_NAME = \"t5-small\"  # Hoặc \"t5-base\", \"t5-large\", \"google/mt5-small\" (cho nhiều ngôn ngữ)\n",
    "WIKI_PAGE_TITLE = \"Artificial intelligence\" # Thay đổi thành tiêu đề trang Wikipedia bạn muốn tóm tắt\n",
    "WIKI_LANGUAGE = 'en'      # Đặt ngôn ngữ ('vi' cho tiếng Việt, 'en' cho tiếng Anh,...)\n",
    "MAX_OUTPUT_LENGTH = 300   # Độ dài tối đa của bản tóm tắt (số lượng token)\n",
    "MIN_OUTPUT_LENGTH = 50    # Độ dài tối thiểu của bản tóm tắt\n",
    "NUM_BEAMS = 5             # Sử dụng beam search để tạo kết quả tốt hơn (thường 4-5)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Sử dụng GPU nếu có\n",
    "\n",
    "print(f\"Cấu hình:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Trang Wikipedia: '{WIKI_PAGE_TITLE}' ({WIKI_LANGUAGE})\")\n",
    "print(f\"  Độ dài tóm tắt: [{MIN_OUTPUT_LENGTH}, {MAX_OUTPUT_LENGTH}] tokens\")\n",
    "print(f\"  Thiết bị: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fce7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = \"./t5_small_local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dccd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model và Tokenizer đã tải xong và sẵn sàng trên thiết bị: cpu\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval() # Chuyển sang chế độ đánh giá\n",
    "print(\"Model và Tokenizer đã tải xong và sẵn sàng trên thiết bị:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8bbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(page_title, language='vi'):\n",
    "    \"\"\"Lấy nội dung tóm tắt (summary) hoặc toàn bộ nội dung từ trang Wikipedia.\"\"\"\n",
    "    content = None\n",
    "    page_obj = None\n",
    "    try:\n",
    "        wikipedia.set_lang(language) # Đặt ngôn ngữ\n",
    "        # Thử lấy trang, cho phép gợi ý và chuyển hướng\n",
    "        page_obj = wikipedia.page(page_title, auto_suggest=True, redirect=True)\n",
    "\n",
    "        # Lấy toàn bộ nội dung\n",
    "        content = page_obj.content\n",
    "        print(f\"Đã tìm thấy và lấy nội dung trang: '{page_obj.title}' (URL: {page_obj.url})\")\n",
    "        # Kiểm tra xem nội dung có rỗng không\n",
    "        if not content or content.isspace():\n",
    "             print(f\"Cảnh báo: Nội dung trang '{page_obj.title}' có vẻ rỗng.\")\n",
    "             content = None # Đặt lại thành None nếu rỗng\n",
    "\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"LỖI: Không tìm thấy trang Wikipedia với tiêu đề khớp chính xác hoặc gần đúng với '{page_title}'.\")\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        print(f\"LỖI: Tiêu đề '{page_title}' không rõ ràng (Disambiguation).\")\n",
    "        print(\"Các trang có thể liên quan (tối đa 5):\")\n",
    "        for i, option in enumerate(e.options[:5]):\n",
    "             print(f\"  {i+1}. {option}\")\n",
    "        print(\"Vui lòng thử lại với một trong các tiêu đề cụ thể hơn ở trên.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "         print(f\"LỖI MẠNG: Không thể kết nối tới Wikipedia. Chi tiết: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"LỖI không xác định khi truy cập Wikipedia: {type(e).__name__} - {e}\")\n",
    "\n",
    "    return content, page_obj # Trả về cả nội dung và đối tượng trang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d2f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, model, tokenizer, max_out_len, min_out_len, num_beams, device, model_name=\"t5\"):\n",
    "    \"\"\"Tóm tắt văn bản đầu vào sử dụng model T5 đã tải.\"\"\"\n",
    "    if not text or text.isspace():\n",
    "        print(\"Cảnh báo: Không có nội dung hợp lệ để tóm tắt.\")\n",
    "        return \n",
    "       \n",
    "    # Xác định tiền tố dựa trên model (đa số T5 dùng \"summarize: \")\n",
    "    # Một số model đa ngôn ngữ (như mT5) có thể không cần hoặc dùng tiền tố khác\n",
    "    prefix = \"summarize: \"\n",
    "    if \"mt5\" in model_name.lower():\n",
    "        print(\"Phát hiện model mT5, không sử dụng tiền tố 'summarize: ' (hoặc thử nghiệm)\")\n",
    "\n",
    "    input_text = prefix + text\n",
    "\n",
    "    # Tokenize văn bản đầu vào\n",
    "    # Giới hạn độ dài đầu vào quan trọng cho T5 (512 hoặc 1024 là phổ biến)\n",
    "    # Kiểm tra max_position_embeddings của model nếu không chắc\n",
    "    try:\n",
    "      input_max_length = tokenizer.model_max_length\n",
    "      if input_max_length > 2048: # Giới hạn hợp lý phòng trường hợp model config lạ\n",
    "          input_max_length = 1024\n",
    "      print(f\"Độ dài tối đa đầu vào cho tokenizer: {input_max_length}\")\n",
    "    except AttributeError:\n",
    "      input_max_length = 1024 # Giá trị mặc định an toàn\n",
    "      print(f\"Không tìm thấy model_max_length, sử dụng mặc định: {input_max_length}\")\n",
    "\n",
    "\n",
    "    # Token hóa đầu vào\n",
    "    input_ids = tokenizer.encode(input_text,\n",
    "                                 return_tensors='pt',\n",
    "                                 max_length=input_max_length,\n",
    "                                 truncation=True,\n",
    "                                 padding='longest').to(device)\n",
    "\n",
    "    input_token_length = input_ids.shape[1]\n",
    "    print(f\"Độ dài token đầu vào thực tế (sau khi cắt nếu cần): {input_token_length}\")\n",
    "    if input_token_length == input_max_length:\n",
    "        print(\"Đầu vào đã bị cắt bớt do dài hơn giới hạn của tokenizer.\")\n",
    "\n",
    "    print(f\"Đang tạo tóm tắt (max_len={max_out_len}, min_len={min_out_len}, num_beams={num_beams})...\")\n",
    "\n",
    "    # Tạo tóm tắt sử dụng phương thức generate của model\n",
    "    summary = \"Lỗi trong quá trình tạo tóm tắt.\" # Giá trị mặc định nếu có lỗi\n",
    "    try:\n",
    "        with torch.no_grad(): # Không cần tính gradient khi inference\n",
    "            summary_ids = model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_out_len + 2, # Thêm chút không gian cho token đặc biệt có thể xuất hiện\n",
    "                min_length=min_out_len,\n",
    "                num_beams=num_beams,\n",
    "                length_penalty=2.0,     # Khuyến khích câu dài hơn một chút (có thể điều chỉnh)\n",
    "                early_stopping=True     # Dừng sớm khi hội tụ\n",
    "            )\n",
    "    \n",
    "        # Giải mã (decode) các token output thành văn bản\n",
    "        print(\"Đang giải mã kết quả...\")\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nLỖI trong quá trình model.generate() hoặc decode(): {type(e).__name__} - {e}\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf9a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tìm thấy và lấy nội dung trang: 'Artificial intelligence' (URL: https://en.wikipedia.org/wiki/Artificial_intelligence)\n",
      "\n",
      "Đã lấy được nội dung cho 'Artificial intelligence'.\n",
      "\n",
      "--- 500 ký tự đầu của nội dung gốc ---\n",
      "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically\n",
      "associated with human intelligence, such as learning, reasoning, problem-solving, perception, and\n",
      "decision-making. It is a field of research in computer science that develops and studies methods and\n",
      "software that enable machines to perceive their environment and use learning and intelligence to\n",
      "take actions that maximize their chances of achieving defined goals. High-profile applications of AI\n",
      "incl...\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm để lấy nội dung\n",
    "wiki_content, wiki_page = get_wikipedia_content(WIKI_PAGE_TITLE, language=WIKI_LANGUAGE)\n",
    "\n",
    "# Kiểm tra xem nội dung có lấy được không\n",
    "if wiki_content:\n",
    "    print(f\"\\nĐã lấy được nội dung cho '{wiki_page.title}'.\")\n",
    "    # In ra một vài dòng đầu tiên của nội dung gốc\n",
    "    print(\"\\n--- 500 ký tự đầu của nội dung gốc ---\")\n",
    "    print(textwrap.fill(wiki_content[:500] + \"...\", width=100))\n",
    "else:\n",
    "    print(f\"\\nKhông lấy được nội dung cho '{WIKI_PAGE_TITLE}'. Không thể tiếp tục tóm tắt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7447f11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ dài tối đa đầu vào cho tokenizer: 512\n",
      "Độ dài token đầu vào thực tế (sau khi cắt nếu cần): 512\n",
      "Đầu vào đã bị cắt bớt do dài hơn giới hạn của tokenizer.\n",
      "Đang tạo tóm tắt (max_len=300, min_len=50, num_beams=5)...\n",
      "Đang giải mã kết quả...\n",
      "\n",
      "======================================== BẢN TÓM TẮT ========================================\n",
      "AI is a field of research in computer science that develops and studies methods and software that\n",
      "enable machines to perceive their environment. high-profile applications include advanced web search\n",
      "engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix);\n",
      "virtual assistants (e.g., Google Assistant, Siri, and Alexa); generative and creative tools (e.g.,\n",
      "language models and AI art)\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Chỉ chạy tóm tắt nếu có nội dung\n",
    "generated_summary = None\n",
    "if wiki_content:\n",
    "    # Thực hiện tóm tắt\n",
    "    generated_summary = summarize_text(\n",
    "        wiki_content,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        MAX_OUTPUT_LENGTH,\n",
    "        MIN_OUTPUT_LENGTH,\n",
    "        NUM_BEAMS,\n",
    "        DEVICE,\n",
    "        model_name=MODEL_NAME # Truyền tên model để xử lý prefix nếu cần\n",
    "    )\n",
    "    # In kết quả tóm tắt\n",
    "    print(\"\\n\" + \"=\"*40 + \" BẢN TÓM TẮT \" + \"=\"*40)\n",
    "    if generated_summary:\n",
    "        print(textwrap.fill(generated_summary, width=100))\n",
    "    else:\n",
    "        print(\"Không tạo được bản tóm tắt.\")\n",
    "    print(\"=\"*93)\n",
    "\n",
    "else:\n",
    "    print(\"\\nKhông có nội dung từ Wikipedia.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
